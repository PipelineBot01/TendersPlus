{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "64d1f7bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from nltk.corpus import stopwords\n",
    "STOP_WORDS = stopwords.words('english')\n",
    "\n",
    "with open(\"../../conf/stop_words.json\", \"r\", encoding='utf-8') as f:\n",
    "    data = json.loads(f.read())\n",
    "    PROJECT_STOP_WORDS = data['PROJECT_STOP_WORDS']\n",
    "\n",
    "\n",
    "def normalize(input_df, target_col, method='proportion'):\n",
    "    assert method in ['proportion', 'max-min', 'rank'], f'{method} not in method list'\n",
    "    if method == 'proportion':\n",
    "        input_df[target_col] = input_df[target_col] / (input_df[target_col].sum())\n",
    "    elif method == 'max-min':\n",
    "        input_df[target_col] = (input_df[target_col] - input_df[target_col].min()\n",
    "                                ) / (input_df[target_col].max() - input_df[target_col].min())\n",
    "    elif method == 'rank':\n",
    "        input_df[target_col] = 1 + 9 / (input_df[target_col].max() - input_df[target_col].min()) * (\n",
    "                input_df[target_col] - input_df[target_col].min())\n",
    "        input_df[target_col] = input_df[target_col].astype(int) * 2\n",
    "        input_df.loc[input_df[target_col] < 3, target_col] = 3\n",
    "        input_df.loc[input_df[target_col] > 10, target_col] = 10\n",
    "    return input_df\n",
    "\n",
    "\n",
    "def filter_words(pos_tagged, lemmatizer):\n",
    "    words = []\n",
    "    noun = list(filter(\n",
    "        lambda x: x[0] not in STOP_WORDS and (x[1].startswith('NN') or x[1].startswith('JJ')),\n",
    "        pos_tagged))\n",
    "    for word, pos in noun:\n",
    "        if pos.startswith('NN'):\n",
    "            word = lemmatizer.lemmatize(word, pos='n')\n",
    "        elif pos.startswith('JJ'):\n",
    "            word = lemmatizer.lemmatize(word, pos='a')\n",
    "        if word not in PROJECT_STOP_WORDS:\n",
    "            words.append(word)\n",
    "    return words\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a5246869",
   "metadata": {},
   "outputs": [],
   "source": [
    "KW_MODEL = KeyBERT()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "736f5d4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "from typing import List, Tuple\n",
    "import nltk\n",
    "import numpy as np, pandas as pd\n",
    "from keybert._model import KeyBERT\n",
    "\n",
    "\n",
    "RE_SYMBOL = \"[`~!@#$^&*()=|{}':;',\\\\[\\\\].<>/?~！@#￥……&*（）\\-–——|{}【】‘’；：”“'。，、？%+_]\"\n",
    "RE_UPPER = '[A-Z]{2,}'\n",
    "RE_WEIGHT_RULE = r'\\((.*?)\\)'\n",
    "\n",
    "class KeyExtractor:\n",
    "    def __init__(self):\n",
    "        self.kw_model = KW_MODEL\n",
    "\n",
    "    def __preprocess(self, text: str) -> str:\n",
    "        text = re.sub(RE_SYMBOL, ' ', text)\n",
    "        text = re.sub(RE_UPPER, '', text)\n",
    "        return text.lower()\n",
    "\n",
    "    def __split_words(self, x: pd.DataFrame) -> pd.DataFrame:\n",
    "        x = x.replace('\\'', '')\n",
    "        return x.split()\n",
    "\n",
    "    def __remove_keywords(self, row: pd.DataFrame) -> pd.DataFrame:\n",
    "        row['text'] = row['text'].replace(row['key'], '')\n",
    "        return row\n",
    "\n",
    "    def __get_tags(self, df: pd.DataFrame) -> List[Tuple[str, float]]:\n",
    "        '''\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        df: pd.DataFrame, input dataframe\n",
    "\n",
    "        This function will call KeyBert to extract the keyword from text description of a\n",
    "        tender, return a list with tuple[keyword, weight]. There are three keyword extraction\n",
    "        strategies:\n",
    "        1.  When the text description is intact, Maximal Marginal Relevance function with a low\n",
    "            diversity value will be called to extract several similar keywords or phrases.\n",
    "        2.  If above function return empty list, the normal keyword extraction function will be\n",
    "            called to extract single key word from text.\n",
    "        3.  If above two functions cannot extract any keyword, an empty tag \"[none_tag]\" will be\n",
    "            returned.\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        List[Tuple[str, float]], list of key-weight tuples, with key as extracted keywords,\n",
    "        weight as the assessed weight of the corresponding keyword.\n",
    "        '''\n",
    "\n",
    "        keywords = self.kw_model.extract_keywords(df['text'],\n",
    "                                                  keyphrase_ngram_range=(1, 3),\n",
    "                                                  stop_words='english',\n",
    "                                                  use_mmr=True,\n",
    "                                                  diversity=0.2)\n",
    "        if len(keywords) == 0:\n",
    "            keywords = self.kw_model.extract_keywords(df['text'], keyphrase_ngram_range=(1, 3), stop_words='english')\n",
    "        return keywords if len(keywords) > 0 else [('[none_tag]', 1)]\n",
    "\n",
    "    def __convert_word_type(self, text: str) -> str:\n",
    "        text = self.__preprocess(text)\n",
    "        token = nltk.word_tokenize(text)\n",
    "        lemmatizer = nltk.stem.WordNetLemmatizer()\n",
    "        pos_tagged = nltk.pos_tag(token)\n",
    "        text = filter_words(pos_tagged, lemmatizer)\n",
    "        return ' '.join(text)\n",
    "\n",
    "    def __agg_tags(self, input_df: pd.DataFrame, target_col: str) -> pd.DataFrame:\n",
    "        '''\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        input_df: pd.DataFrame, input dataframe\n",
    "        target_col: str, KeyBert result column for aggregation,\n",
    "\n",
    "        This function will count the total weight for each single word from\n",
    "        tenders, according to the result by KeyBert. Weight from same word\n",
    "        will be added and the one with the highest weight for each tenders\n",
    "        will be returned as the candidate tag.\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        A dataframe with the shape of n*4. PKs are [items, key_orig]\n",
    "        Columns: 'items': matching with each tenders project.\n",
    "                 'key': extracted stem with the highest weight.\n",
    "                 'value': total weight for the final stem\n",
    "        '''\n",
    "\n",
    "        input_df[target_col] = input_df[target_col].astype(str)\n",
    "\n",
    "        # Extract and reformat term-weight set\n",
    "        tmp_df = input_df[target_col].str.extractall(RE_WEIGHT_RULE).reset_index().reset_index()\n",
    "        split_result = tmp_df[0].str.split(',', expand=True).rename(columns={0: 'key',\n",
    "                                                                             1: 'value'}).reset_index()\n",
    "\n",
    "        merge_df = tmp_df.merge(split_result, on='index').drop('index', axis=1).rename(columns={'level_0': 'items'})\n",
    "        del tmp_df, split_result\n",
    "\n",
    "        merge_df['key'] = merge_df['key'].map(self.__split_words)\n",
    "        mapping_df = merge_df.explode('key')[['items', 'key', 'value']]\n",
    "\n",
    "        # Compute weight according to each word and ordering\n",
    "        mapping_df['value'] = mapping_df['value'].astype(float)\n",
    "        sum_df = mapping_df.groupby(['items', 'key'])['value'].sum().reset_index().sort_values(\n",
    "            ['items', 'value'], ascending=False)\n",
    "\n",
    "        # Sampling top key\n",
    "        removed_df = sum_df[~sum_df['key'].isin(PROJECT_STOP_WORDS)]\n",
    "        removed_df = sum_df if sum_df.empty else removed_df\n",
    "\n",
    "        key_df = removed_df.groupby(['items']).head(1)[['items', 'key']]\n",
    "        merge_df = sum_df.merge(key_df, on=['items', 'key'])\n",
    "\n",
    "        return merge_df\n",
    "\n",
    "    def extract_label(self, input_df, pk: str, iteration_time: int) -> pd.DataFrame:\n",
    "        '''\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        input_df: pd.DataFrame, input dataframe\n",
    "        pk: str, name of the primary key for the input_df\n",
    "        iteration_time: int, current iteration time\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        pd.DataFrame, output dataframe with the extracted key in this iteration and remained text col.\n",
    "        '''\n",
    "\n",
    "        # Get keywords in one around\n",
    "        input_df['raw_result'] = input_df.apply(self.__get_tags, axis=1)\n",
    "\n",
    "        # Aggregate keywords\n",
    "        merge_df = self.__agg_tags(input_df, 'raw_result')\n",
    "        first_df = input_df[['index', 'text']].merge(merge_df, left_on='index', right_on='items', how='left')\n",
    "\n",
    "        # Generating new text\n",
    "        df = input_df.drop('text', axis=1)\n",
    "        first_df = first_df[first_df['key'].notna()].apply(self.__remove_keywords, axis=1).rename(\n",
    "            columns={'key': f'key_{iteration_time}'}).drop('items', axis=1)\n",
    "        df = df.merge(first_df, on='index', how='left')\n",
    "\n",
    "        return df[[pk, f'key_{iteration_time}', 'text']]\n",
    "\n",
    "    def get_tags(self, input_df: pd.DataFrame, pk: str, text_col: str, iterations=10) -> pd.DataFrame:\n",
    "        '''\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        input_df: pd.DataFrame,\n",
    "        pk: str, name of the primary key for the input_df\n",
    "        text_col: str, name of tenders' text description column\n",
    "        iterations: iterations for extraction process\n",
    "\n",
    "        This function will generate iteration times of keywords for each tender,\n",
    "        keys may include empty value if KeyBert cannot extract any keyword from\n",
    "        the text.\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        pd.DataFrame, original dataframe appending with key columns: [key_0, key_1 ...]\n",
    "        '''\n",
    "\n",
    "        assert text_col in input_df.columns, f'Missing column names \"{text_col}\".'\n",
    "        tmp_df = input_df[input_df[text_col].notna()].copy()\n",
    "        tmp_df[text_col] = tmp_df[text_col].map(lambda x: self.__preprocess(x))\n",
    "        tmp_df[text_col] = tmp_df[text_col].map(lambda x: self.__convert_word_type(x))\n",
    "\n",
    "        # Remove pure numbers, e.g., 2014, 20,000\n",
    "        display(tmp_df[text_col])\n",
    "        tmp_df[text_col] = tmp_df[text_col].map(lambda x: re.sub(r'\\s*(\\.:,|\\d+)\\s*', '', x))\n",
    "        tmp_df = tmp_df.reset_index(drop=True).reset_index()\n",
    "        tmp_df = tmp_df[[pk, text_col, 'index']]\n",
    "\n",
    "        for i in range(iterations):\n",
    "            tmp_df = self.extract_label(tmp_df, pk, i)\n",
    "            input_df['text'] = tmp_df['text'].copy()\n",
    "            input_df = input_df.merge(tmp_df[['_id', f'key_{i}']], on=pk, how='left')\n",
    "            tmp_df = tmp_df[(tmp_df[f'key_{i}'] != '[none_tag]') & (tmp_df['text'].notna())].reindex().reset_index()\n",
    "\n",
    "        input_df = input_df.replace('[none_tag]', np.nan)\n",
    "        return input_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2cda1190",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_df = pd.read_csv('../assets/tenders_info.csv')\n",
    "input_df['text'] = input_df['Description'] + '.' + input_df['Title']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6009ac6d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1837    national preschool census calendar year possib...\n",
       "1838    seek proposal indigenous youth employment cons...\n",
       "Name: text, dtype: object"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\24966\\AppData\\Local\\Temp/ipykernel_1280/293561348.py:178: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  input_df['text'] = tmp_df['text'].copy()\n"
     ]
    }
   ],
   "source": [
    "ke = KeyExtractor()\n",
    "re_df = ke.get_tags(input_df[1837:1839], '_id', 'text')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "84eec52a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>_id</th>\n",
       "      <th>Agency</th>\n",
       "      <th>Title</th>\n",
       "      <th>Publish Date</th>\n",
       "      <th>Close Date</th>\n",
       "      <th>Category</th>\n",
       "      <th>Category_sub</th>\n",
       "      <th>Description</th>\n",
       "      <th>Eligibility</th>\n",
       "      <th>Value</th>\n",
       "      <th>...</th>\n",
       "      <th>key_0</th>\n",
       "      <th>key_1</th>\n",
       "      <th>key_2</th>\n",
       "      <th>key_3</th>\n",
       "      <th>key_4</th>\n",
       "      <th>key_5</th>\n",
       "      <th>key_6</th>\n",
       "      <th>key_7</th>\n",
       "      <th>key_8</th>\n",
       "      <th>key_9</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6162aa1fe1b7f5c73e6fe07a</td>\n",
       "      <td>NaN</td>\n",
       "      <td>National Preschool Census - Aboriginal and Tor...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Education and Training Services</td>\n",
       "      <td>NaN</td>\n",
       "      <td>The objective of the National Preschool Census...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>preschool</td>\n",
       "      <td>census</td>\n",
       "      <td>aboriginal</td>\n",
       "      <td>strait</td>\n",
       "      <td>islander</td>\n",
       "      <td>national</td>\n",
       "      <td>extension</td>\n",
       "      <td>year</td>\n",
       "      <td>possible</td>\n",
       "      <td>calendar</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>6162aa1fe1b7f5c73e6fe07b</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Request for Tender for the Provision of an Ind...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Education and Training Services</td>\n",
       "      <td>NaN</td>\n",
       "      <td>The RFT seeks to proposals to engage Indigenou...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>youth</td>\n",
       "      <td>employment</td>\n",
       "      <td>indigenous</td>\n",
       "      <td>consultant</td>\n",
       "      <td>department</td>\n",
       "      <td>workplace</td>\n",
       "      <td>relation</td>\n",
       "      <td>proposal</td>\n",
       "      <td>request</td>\n",
       "      <td>provision</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows × 22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                        _id Agency  \\\n",
       "0  6162aa1fe1b7f5c73e6fe07a    NaN   \n",
       "1  6162aa1fe1b7f5c73e6fe07b    NaN   \n",
       "\n",
       "                                               Title Publish Date Close Date  \\\n",
       "0  National Preschool Census - Aboriginal and Tor...          NaN        NaN   \n",
       "1  Request for Tender for the Provision of an Ind...          NaN        NaN   \n",
       "\n",
       "                          Category Category_sub  \\\n",
       "0  Education and Training Services          NaN   \n",
       "1  Education and Training Services          NaN   \n",
       "\n",
       "                                         Description Eligibility Value  ...  \\\n",
       "0  The objective of the National Preschool Census...         NaN   NaN  ...   \n",
       "1  The RFT seeks to proposals to engage Indigenou...         NaN   NaN  ...   \n",
       "\n",
       "       key_0       key_1       key_2       key_3       key_4      key_5  \\\n",
       "0  preschool      census  aboriginal      strait    islander   national   \n",
       "1      youth  employment  indigenous  consultant  department  workplace   \n",
       "\n",
       "       key_6     key_7     key_8      key_9  \n",
       "0  extension      year  possible   calendar  \n",
       "1   relation  proposal   request  provision  \n",
       "\n",
       "[2 rows x 22 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "re_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0af1f258",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
