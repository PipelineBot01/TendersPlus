{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e6b0b95f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "from typing import List, Tuple\n",
    "import nltk\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from keybert._model import KeyBERT\n",
    "from nltk.corpus import stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "75372a0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "RE_SYMBOL = \"[`~!@#$^&*()=|{}':;',\\\\[\\\\].<>/?~！@#￥……&*（）\\-–——|{}【】‘’；：”“'。，、？%+_]\"\n",
    "RE_UPPER = '[A-Z]{2,}'\n",
    "RE_WEIGHT_RULE = r'\\((.*?)\\)'\n",
    "PROJECT_STOP_WORDS = [\n",
    "    \"activity\",\n",
    "    \"agreement\",\n",
    "    \"aim\",\n",
    "    \"australasian\",\n",
    "    \"australia\",\n",
    "    \"australian\",\n",
    "    \"eligible\",\n",
    "    \"government\",\n",
    "    \"grant\",\n",
    "    \"level\",\n",
    "    \"list\",\n",
    "    \"mission\",\n",
    "    \"objective\",\n",
    "    \"priority\",\n",
    "    \"processing\",\n",
    "    \"program\",\n",
    "    \"programme\",\n",
    "    \"project\",\n",
    "    \"refer\",\n",
    "    \"research\",\n",
    "    \"round\",\n",
    "    \"service\",\n",
    "    \"tender\",\n",
    "    \"title\",\n",
    "    \"-\",\n",
    "    \"-\",\n",
    "    \"/\",\n",
    "    \"’\",\n",
    "    \"•\"\n",
    "  ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3e9ab773",
   "metadata": {},
   "outputs": [],
   "source": [
    "kw_model = KeyBERT()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "fa4bfb8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "NN = 0\n",
    "class KeyExtractor:\n",
    "    def __init__(self, kw_model):\n",
    "        self.STOP_WORDS = stopwords.words('english') + PROJECT_STOP_WORDS\n",
    "        self.kw_model = kw_model\n",
    "\n",
    "    def __preprocess(self, text: str):\n",
    "        text = re.sub(RE_SYMBOL, ' ', text)\n",
    "        text = re.sub(RE_UPPER, '', text)\n",
    "        return text.lower()\n",
    "\n",
    "    def __split_words(self, x: pd.DataFrame) -> pd.DataFrame:\n",
    "        x = x.replace('\\'', '')\n",
    "        return x.split()\n",
    "\n",
    "    def __remove_keywords(self, row: pd.DataFrame) -> pd.DataFrame:\n",
    "        row['text'] = row['text'].replace(row['key'], '')\n",
    "        return row\n",
    "\n",
    "    def __get_tags(self, df: pd.DataFrame) -> List[Tuple[str, float]]:\n",
    "        '''\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        df: pd.DataFrame, input dataframe\n",
    "\n",
    "        This function will call KeyBert to extract the keyword from text description of a\n",
    "        tender, return a list with tuple[keyword, weight]. There are three keyword extraction\n",
    "        strategies:\n",
    "        1.  When the text description is intact, Maximal Marginal Relevance function with a low\n",
    "            diversity value will be called to extract several similar keywords or phrases.\n",
    "        2.  If above function return empty list, the normal keyword extraction function will be\n",
    "            called to extract single key word from text.\n",
    "        3.  If above two functions cannot extract any keyword, an empty tag \"[none_tag]\" will be\n",
    "            returned.\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        List[Tuple[str, float]], list of key-weight tuples, with key as extracted keywords,\n",
    "        weight as the assessed weight of the corresponding keyword.\n",
    "        '''\n",
    "\n",
    "        keywords = self.kw_model.extract_keywords(df['text'],\n",
    "                                                  keyphrase_ngram_range=(1, 3),\n",
    "                                                  stop_words='english',\n",
    "                                                  use_mmr=True,\n",
    "                                                  diversity=0.2)\n",
    "        if not keywords: return [('[none_tag]', 1)]\n",
    "        if len(keywords) == 0:\n",
    "            keywords = self.kw_model.extract_keywords(df['text'], keyphrase_ngram_range=(1, 3), stop_words='english')\n",
    "        return keywords if len(keywords) > 0 else [('[none_tag]', 1)]\n",
    "\n",
    "    def __convert_word_type(self, text):\n",
    "        text = self.__preprocess(text)\n",
    "        token = nltk.word_tokenize(text)\n",
    "        lemmatizer = nltk.stem.WordNetLemmatizer()\n",
    "        pos_tagged = nltk.pos_tag(token)\n",
    "        words = []\n",
    "        Noun = list(filter(\n",
    "            lambda x: x[0] not in self.STOP_WORDS and x[0] != '/' and (x[1].startswith('NN') or x[1].startswith('JJ')),\n",
    "            pos_tagged))\n",
    "        for word, pos in Noun:\n",
    "            if pos.startswith('NN'):\n",
    "                word = lemmatizer.lemmatize(word, pos='n')\n",
    "            elif pos.startswith('JJ'):\n",
    "                word = lemmatizer.lemmatize(word, pos='a')\n",
    "            words.append(word)\n",
    "        text = \" \".join(words)\n",
    "        return text\n",
    "\n",
    "    def __agg_tags(self, input_df: pd.DataFrame, target_col: str) -> pd.DataFrame:\n",
    "        '''\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        input_df: pd.DataFrame, input dataframe\n",
    "        target_col: str, KeyBert result column for aggregation,\n",
    "\n",
    "        This function will count the total weight for each single stem by\n",
    "        tenders, according to the result from KeyBert. Weight from same stem\n",
    "        will be added and the stem with the highest weight for each tenders\n",
    "        will be returned as the candidate tag. One thing to node, if there are\n",
    "        few words in a tender that pointed to the highest stem\n",
    "        (e.g., orig_word: [manager, management, managing] -> stem: [manage]),\n",
    "        all these words will be returned.\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        A dataframe with the shape of n*4. PKs are [items, key_orig]\n",
    "        Columns: 'items': matching with each tenders project.\n",
    "                 'key': extracted stem with the highest weight.\n",
    "                 'key_orig': original word corresponding to the key.\n",
    "                 'value': total weight for the final stem\n",
    "        '''\n",
    "\n",
    "        input_df[target_col] = input_df[target_col].astype(str)\n",
    "\n",
    "        # Extract and reformat term-weight set\n",
    "        tmp_df = input_df[target_col].str.extractall(RE_WEIGHT_RULE).reset_index().reset_index()\n",
    "        split_result = tmp_df[0].str.split(',', expand=True).rename(columns={0: 'key',\n",
    "                                                                             1: 'value'}).reset_index()\n",
    "\n",
    "        merge_df = tmp_df.merge(split_result, on='index').drop('index', axis=1).rename(columns={'level_0': 'items'})\n",
    "        del tmp_df, split_result\n",
    "\n",
    "        merge_df['key'] = merge_df['key'].map(self.__split_words)\n",
    "        mapping_df = merge_df.explode('key')[['items', 'key', 'value']]\n",
    "\n",
    "        # Compute weight according to each word and ordering\n",
    "        mapping_df['value'] = mapping_df['value'].astype(float)\n",
    "        sum_df = mapping_df.groupby(['items', 'key'])['value'].sum().reset_index().sort_values(\n",
    "            ['items', 'value'], ascending=False)\n",
    "\n",
    "        # Sampling top key\n",
    "        removed_df = sum_df[~sum_df['key'].isin(PROJECT_STOP_WORDS)]\n",
    "        removed_df = sum_df if sum_df.empty else removed_df\n",
    "        key_df = sum_df.groupby(['items']).head(1)[['items', 'key']]\n",
    "        merge_df = sum_df.merge(key_df, on=['items', 'key'])\n",
    "        return merge_df\n",
    "\n",
    "    def extract_label(self, df, pk: str, iteration_time: int):\n",
    "        # Get keywords in one around\n",
    "        df['raw_result'] = df.apply(self.__get_tags, axis=1)\n",
    "\n",
    "        # Aggregate keywords\n",
    "        merge_df = self.__agg_tags(df, 'raw_result')\n",
    "        first_df = df[['index', 'text']].merge(merge_df, left_on='index', right_on='items', how='left')\n",
    "\n",
    "        # Generating new text\n",
    "        df = df.drop('text', axis=1)\n",
    "        first_df = first_df[first_df['key'].notna()].apply(self.__remove_keywords, axis=1).rename(\n",
    "            columns={'key': f'key_{iteration_time}'}).drop('items', axis=1)\n",
    "        df = df.merge(first_df, on='index', how='left')\n",
    "\n",
    "        return df[[pk, f'key_{iteration_time}', 'text']]\n",
    "\n",
    "    def get_label_by_iteration(self, input_df: pd.DataFrame, pk: str, text_col: str, iterations=10) -> pd.DataFrame:\n",
    "        '''\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        input_df: pd.DataFrame,\n",
    "        pk: str, name of the primary key for the input_df\n",
    "        text_col: str, name of tenders' text description column\n",
    "        iterations: iterations for extraction process\n",
    "\n",
    "        This function will generate iteration times of keywords for each tender,\n",
    "        keys may include empty value if KeyBert cannot extract any keyword from\n",
    "        the text.\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        pd.DataFrame, original dataframe appending with key columns:\n",
    "                                [key_0, key_1, key_2...]\n",
    "        '''\n",
    "\n",
    "        assert text_col in input_df.columns, f'Missing column names \"{text_col}\".'\n",
    "        tmp_df = input_df[input_df[text_col].notna()].copy()\n",
    "        tmp_df[text_col] = tmp_df[text_col].map(lambda x: self.__preprocess(x))\n",
    "        tmp_df[text_col] = tmp_df[text_col].map(lambda x: self.__convert_word_type(x))\n",
    "\n",
    "        # Remove pure numbers, e.g., 2014, 20,000\n",
    "        tmp_df[text_col] = tmp_df[text_col].map(lambda x: re.sub(r'\\s*(\\.:,|\\d+)\\s*', '', x))\n",
    "        tmp_df = tmp_df.reset_index(drop=True).reset_index()\n",
    "        tmp_df = tmp_df[[pk, text_col, 'index']]\n",
    "        \n",
    "        for i in range(iterations):\n",
    "            tmp_df = self.extract_label(tmp_df, pk, i)\n",
    "            input_df['text'] = tmp_df['text']\n",
    "            input_df = input_df.merge(tmp_df[['_id', f'key_{i}']], on=pk, how='left')\n",
    "            tmp_df = tmp_df[(tmp_df[f'key_{i}']!='[none_tag]')&(tmp_df['text'].notna())].reindex().reset_index()\n",
    "\n",
    "        input_df = input_df.replace('[none_tag]', np.nan)\n",
    "        return input_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "082df0b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_df = pd.read_csv('Data/tenders_info.csv')\n",
    "input_df['Description'] = input_df['Description'].fillna('')\n",
    "input_df['text'] = input_df['Description'] + '.' + input_df['Title']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f47460c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "ke = KeyExtractor(kw_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8b03baee",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\24966\\AppData\\Local\\Temp/ipykernel_13464/1800324737.py:169: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  input_df['text'] = tmp_df['text']\n"
     ]
    }
   ],
   "source": [
    "return_df = ke.get_label_by_iteration(input_df[1837:1839], '_id', 'text')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d9703761",
   "metadata": {},
   "outputs": [],
   "source": [
    "return_df.to_csv('tt.csv', index=0, encoding='utf-8_sig')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3ca9b539",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>_id</th>\n",
       "      <th>Agency</th>\n",
       "      <th>Title</th>\n",
       "      <th>Publish Date</th>\n",
       "      <th>Close Date</th>\n",
       "      <th>Category</th>\n",
       "      <th>Category_sub</th>\n",
       "      <th>Description</th>\n",
       "      <th>Eligibility</th>\n",
       "      <th>Value</th>\n",
       "      <th>...</th>\n",
       "      <th>key_0</th>\n",
       "      <th>key_1</th>\n",
       "      <th>key_2</th>\n",
       "      <th>key_3</th>\n",
       "      <th>key_4</th>\n",
       "      <th>key_5</th>\n",
       "      <th>key_6</th>\n",
       "      <th>key_7</th>\n",
       "      <th>key_8</th>\n",
       "      <th>key_9</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6162aa1fe1b7f5c73e6fe07a</td>\n",
       "      <td>NaN</td>\n",
       "      <td>National Preschool Census - Aboriginal and Tor...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Education and Training Services</td>\n",
       "      <td>NaN</td>\n",
       "      <td>The objective of the National Preschool Census...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>preschool</td>\n",
       "      <td>census</td>\n",
       "      <td>aboriginal</td>\n",
       "      <td>strait</td>\n",
       "      <td>islander</td>\n",
       "      <td>national</td>\n",
       "      <td>extension</td>\n",
       "      <td>year</td>\n",
       "      <td>possible</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>6162aa1fe1b7f5c73e6fe07b</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Request for Tender for the Provision of an Ind...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Education and Training Services</td>\n",
       "      <td>NaN</td>\n",
       "      <td>The RFT seeks to proposals to engage Indigenou...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>youth</td>\n",
       "      <td>employment</td>\n",
       "      <td>indigenous</td>\n",
       "      <td>consultant</td>\n",
       "      <td>department</td>\n",
       "      <td>workplace</td>\n",
       "      <td>relation</td>\n",
       "      <td>proposal</td>\n",
       "      <td>request</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows × 22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                        _id  Agency  \\\n",
       "0  6162aa1fe1b7f5c73e6fe07a     NaN   \n",
       "1  6162aa1fe1b7f5c73e6fe07b     NaN   \n",
       "\n",
       "                                               Title  Publish Date  \\\n",
       "0  National Preschool Census - Aboriginal and Tor...           NaN   \n",
       "1  Request for Tender for the Provision of an Ind...           NaN   \n",
       "\n",
       "   Close Date                         Category  Category_sub  \\\n",
       "0         NaN  Education and Training Services           NaN   \n",
       "1         NaN  Education and Training Services           NaN   \n",
       "\n",
       "                                         Description  Eligibility  Value  ...  \\\n",
       "0  The objective of the National Preschool Census...          NaN    NaN  ...   \n",
       "1  The RFT seeks to proposals to engage Indigenou...          NaN    NaN  ...   \n",
       "\n",
       "       key_0       key_1       key_2       key_3       key_4      key_5  \\\n",
       "0  preschool      census  aboriginal      strait    islander   national   \n",
       "1      youth  employment  indigenous  consultant  department  workplace   \n",
       "\n",
       "       key_6     key_7     key_8 key_9  \n",
       "0  extension      year  possible   NaN  \n",
       "1   relation  proposal   request   NaN  \n",
       "\n",
       "[2 rows x 22 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "return_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3d8e522",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
